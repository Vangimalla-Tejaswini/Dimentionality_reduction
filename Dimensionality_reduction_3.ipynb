{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557c7e68",
   "metadata": {},
   "source": [
    "#### Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31a39",
   "metadata": {},
   "source": [
    "Eigenvalues and Eigenvectors: Eigenvalues are scalars associated with eigenvectors that represent how a linear transformation, represented by a matrix, scales those vectors. Eigenvectors are non-zero vectors that only change in scale when a linear transformation is applied to them. In the eigen-decomposition approach, a square matrix is decomposed into eigenvectors and eigenvalues. For example, consider a matrix A:\n",
    "A=mat(1 2,3 4)\n",
    "  \n",
    "The eigenvalues (λ) and corresponding eigenvectors (v) can be found by solving the equation:\n",
    "\n",
    "A⋅v=λ⋅v."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd051a18",
   "metadata": {},
   "source": [
    "#### Q2. What is eigen decomposition and what is its significance in linear algebra?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6352b30",
   "metadata": {},
   "source": [
    "Eigen-decomposition Significance: Eigen-decomposition breaks down a matrix into its constituent eigenvectors and eigenvalues. It's significant because it simplifies many matrix operations, making computations easier. It's often used in solving systems of linear differential equations and in finding powers of matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b2c44",
   "metadata": {},
   "source": [
    "#### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd07cbc",
   "metadata": {},
   "source": [
    "A square matrix is diagonalizable if it has n linearly independent eigenvectors, where n is the dimension of the matrix. This condition ensures that the eigenvectors form a basis for the vector space. A proof involves showing that if a matrix has n linearly independent eigenvectors, it can be decomposed into a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08d538",
   "metadata": {},
   "source": [
    "#### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a226c",
   "metadata": {},
   "source": [
    "The spectral theorem states that for a symmetric matrix, the eigenvalues are real, and there exists an orthogonal matrix whose columns are the eigenvectors of the matrix. This theorem is crucial in the context of eigen-decomposition because it ensures that certain matrices are always diagonalizable. For example, consider the covariance matrix in principal component analysis (PCA), where the spectral theorem guarantees the existence of orthogonal eigenvectors, simplifying the decomposition process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f196531",
   "metadata": {},
   "source": [
    "#### Q5. How do you find the eigenvalues of a matrix and what do they represent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352b8bc",
   "metadata": {},
   "source": [
    "Eigenvalues can be found by solving the characteristic equation \n",
    "det(A−λI)=0, where A is the matrix, λ is the eigenvalue, and I is the identity matrix. They represent how the matrix scales the corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a750142a",
   "metadata": {},
   "source": [
    "#### Q6. What are eigenvectors and how are they related to eigenvalues?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19853f5",
   "metadata": {},
   "source": [
    "Eigenvectors are vectors that only change in scale when a linear transformation (represented by the matrix) is applied. Eigenvalues represent the scaling factor by which the eigenvectors are scaled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50369a2b",
   "metadata": {},
   "source": [
    "#### Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f247a8",
   "metadata": {},
   "source": [
    "Geometric Interpretation: Eigenvectors represent directions in the vector space that remain unchanged (except for scaling) when a transformation is applied. Eigenvalues represent the scaling factor along those directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a82f3",
   "metadata": {},
   "source": [
    "#### Q8. What are some real-world applications of eigen decomposition?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807388c",
   "metadata": {},
   "source": [
    "Eigen-decomposition is used in various fields such as image processing (e.g., eigenfaces for facial recognition), physics (e.g., quantum mechanics), and finance (e.g., portfolio optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee97351",
   "metadata": {},
   "source": [
    "#### Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c17c5",
   "metadata": {},
   "source": [
    "No, a matrix cannot have multiple sets of linearly independent eigenvectors associated with distinct eigenvalues. However, it's possible to have repeated eigenvalues with different corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cee44",
   "metadata": {},
   "source": [
    "#### Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?  Discuss at least three specific applications or techniques that rely on Eigen-Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255dbd30",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA):\n",
    "       PCA uses eigen-decomposition to find the principal components of data, reducing its dimensionality while preserving its variance.\n",
    "#### Spectral Clustering: \n",
    "          Eigen-decomposition is used to find the eigenvectors of similarity matrices in spectral clustering, which helps identify clusters in data.\n",
    "#### Eigenfaces in Facial Recognition: \n",
    "           Eigen-decomposition is used to represent faces as linear combinations of eigenfaces, allowing for efficient facial recognition algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
